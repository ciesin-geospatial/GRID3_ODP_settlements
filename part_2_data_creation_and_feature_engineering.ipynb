{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5fa726",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d68a0b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geo_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb879e8",
   "metadata": {},
   "source": [
    "### Load settlement data, select the hamlet part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a052ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify country code so all output file will be labeled correctly\n",
    "country_alpha_3_code = 'ZMB'\n",
    "\n",
    "# Specify UTM zone EPSG code for this country, so that projection operation in this notebook knows the target CRS\n",
    "country_utm_epsg = 'epsg:32735'\n",
    "\n",
    "# africa albers equal area conic\n",
    "albers_equal_area = 'epsg:102022' # not found\n",
    "\n",
    "default_pcs = country_utm_epsg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45de9a99",
   "metadata": {},
   "source": [
    "---\n",
    "Function `explode_geometry`\n",
    "\n",
    "Parameters: \n",
    "- `gdf`, *GeoDataframe* \n",
    "- `geom_colum`, *str*   (default = 'geometry') \n",
    "- `id_column`, *str*   (default = None, must specify if using drop_duplicates) \n",
    "- `drop_duplicates`, *boolean*   (default = False) \n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe with geometry column exploded into single-polygon/single-linestring objects. Use drop_duplicates in combination with id_column to keep only the the largest shape among the shapes with the same original id.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900a9633",
   "metadata": {},
   "source": [
    "---\n",
    "Function `add_buffer_column`\n",
    "\n",
    "Parameters: \n",
    "- `gdf`, *GeoDataframe* \n",
    "- `buffer_radius`, *int*  (in meters)\n",
    "- `geom_column`, *str*   (default = 'geometry') \n",
    "- `buffer_shape`, *str*   (default = 'round', options: 'round','square','flat') \n",
    "- `proj2`, *str* (default = None, options: any valid crs)\n",
    "- `replace`, *boolean* (default = False)\n",
    "- `return_new_column`, *boolean* (default = False)\n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe with a new buffer column. Set the geometry from which to buffer using `geom_column`. Set buffer radius with `buffer_radius`, units are in meters, the radius can be negative for shrinking shapes, though multiple shapes may be created as a result. Control shape of buffer with `buffer_shape`. If you want the buffer to be based on a projection other than current projection, use `proj2`, it will not affect the projection of the input dataframe, it only applies to the new buffer column. If you want to replace the main geometry column with the newly created buffer column, set `replace` to True. If you want to get the name of the newly created buffer column, set `return_new_column` to True. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbc7e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the shapefile of all settlements\n",
    "settlement_extents = gpd.read_feather('./data/ZMB_grid3_settlement_extents_20201222.feather').to_crs(default_pcs)\n",
    "\n",
    "# Filter down to hamlet settlements (the focus of this false positive prediction workflow)\n",
    "hamlet_settlements = settlement_extents.query('type == \"hamlet\"')[['mgrs_code','geometry']]\n",
    "\n",
    "# Convert the default \"multipolygon\" geometry type to (single)\"polygon\" geometry type\n",
    "hamlet_settlements = explode_geometry(hamlet_settlements, id_column = 'mgrs_code', drop_duplicates = True)\n",
    "\n",
    "hamlet_settlements = add_buffer_column(hamlet_settlements, -40, proj2=None, replace=True)\n",
    "\n",
    "hamlet_settlements = explode_geometry(hamlet_settlements, id_column = 'mgrs_code', drop_duplicates = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eb50f3",
   "metadata": {},
   "source": [
    "### Feature 1:  Google building presence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091d78bf",
   "metadata": {},
   "source": [
    "---\n",
    "Function `read_csv_as_gpd`\n",
    "\n",
    "Parameters: \n",
    "- `df_or_filepath`, *GeoDataframe or str*\n",
    "- `id_column`, *str*   (default = None, if not specified, a UUID column will be generated) \n",
    "- `lon_lat_columns`, *list of str*   (default = \\[\\]) \n",
    "- `attribute_columns`, *list of str*  (default = \\[\\]) \n",
    "- `drop_rows_where_duplicates_in_columns`, *list of str*  (default = \\[\\]) \n",
    "- `keep_which_if_duplicates`, *str*  (default = 'first', options: 'first','last')\n",
    "- `drop_rows_where_nan_in_columns`, *list of str*  (default = \\[\\]) \n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe loaded from a CSV file. Use `drop_rows_where_duplicates_in_columns` in combination with `id_column` and `keep_which_if_duplicates` to keep control the behavior when duplicates are detected in certain columns. Use `drop_rows_where_nan_in_columns` to control the dropping of rows with missing values.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190548b8",
   "metadata": {},
   "source": [
    "---\n",
    "Function `left_spatial_join`\n",
    "\n",
    "Parameters: \n",
    "- `gdf1`, *GeoDataframe*\n",
    "- `gdf2`, *GeoDataframe*   \n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe resulting from the left spatial join of two input GeoDataframes. Spatial join operation uses \"intersection\", right index dropped.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538fb426",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_buildings_layer = read_csv_as_gpd('./data/ZMB_google_buildings_footprint.csv', \n",
    "                                          id_column = None, \n",
    "                                          lon_lat_columns = ['longitude','latitude'], \n",
    "                                          attribute_columns = ['area_in_meters','confidence'],\n",
    "                                          drop_rows_where_duplicates_in_columns = ['longitude','latitude']\n",
    "                                        ).to_crs(default_pcs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66e41b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_buildings_layer = left_spatial_join(google_buildings_layer, hamlet_settlements[['mgrs_code','geometry']])\n",
    "\n",
    "settlements_with_google_builing = google_buildings_layer['mgrs_code'].dropna().unique().tolist()\n",
    "\n",
    "hamlet_settlements.loc[hamlet_settlements['mgrs_code'].isin(settlements_with_google_builing),'google_value'] = 1\n",
    "hamlet_settlements['google_value'] = hamlet_settlements['google_value'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedb9c0b",
   "metadata": {},
   "source": [
    "### Feature 2: Survey building presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa80353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_presence_layer = read_csv_as_gpd('./data/ZM_geos_L1_2019.csv', \n",
    "                                          id_column = 'sid', \n",
    "                                          lon_lat_columns = ['lon','lat'], \n",
    "                                          attribute_columns = ['bp'], \n",
    "                                          drop_rows_where_duplicates_in_columns = ['observer','lat','lon'], \n",
    "                                          drop_rows_where_nan_in_columns = ['lat','lon','bp']\n",
    "                                         ).to_crs(default_pcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b2c03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_presence_layer = add_buffer_column(building_presence_layer, buffer_radius = 100, buffer_shape = 'square', replace=True)\n",
    "\n",
    "hamlet_settlements = left_spatial_join(hamlet_settlements, building_presence_layer[['bp','geometry']])\n",
    "\n",
    "hamlet_settlements['bp_value'] = hamlet_settlements['bp'].map({'Y':1,'N':0})\n",
    "\n",
    "hamlet_settlements = hamlet_settlements.drop('bp', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3560f",
   "metadata": {},
   "source": [
    "### Feature 3: HRSL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a981775",
   "metadata": {},
   "source": [
    "---\n",
    "Function `add_centroid_column`\n",
    "\n",
    "Parameters: \n",
    "- `gdf`, *GeoDataframe* \n",
    "- `geom_column`, *str*   (default = 'geometry') \n",
    "- `proj2`, *str* (default = None, options: any valid crs)\n",
    "- `replace`, *boolean* (default = False)\n",
    "- `return_new_column`, *boolean* (default = False)\n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe with a new centroid column. Set the geometry from which to calculate centroid using `geom_column`. If you want the centroid to be based on a projection other than current projection, use `proj2`, it will not affect the projection of the input dataframe, it only applies to the new centroid column. If you want to replace the main geometry column with the newly created centroid column, set `replace` to True. If you want to get the name of the newly created centroid column, set `return_new_column` to True. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06f66236",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_settlements, centroid_column = add_centroid_column(hamlet_settlements, return_new_column=True)\n",
    "\n",
    "# Since HRSL data is in GCS, convert just the centroid column to WGS84 to facilitate pixel lookup in HRSL raster\n",
    "hamlet_settlements[centroid_column] = hamlet_settlements[centroid_column].to_crs('epsg:4326')\n",
    "\n",
    "hamlet_settlements = get_raster_point_value(hamlet_settlements, centroid_column, raster_filepath = './data/ZMB_HRSL_hasim_20211222.tif', new_column = 'hrsl_value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd802bb",
   "metadata": {},
   "source": [
    "### Feature 4: WSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2880f936",
   "metadata": {},
   "source": [
    "---\n",
    "Function `add_covering_geotiff_column`\n",
    "\n",
    "Parameters: \n",
    "- `gdf`, *GeoDataframe* \n",
    "- `geom_column`, *str* \n",
    "- `geotiff_filepath_column`, *str*\n",
    "- `geotiff_filepath_list`, *list of str* \n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe with a new column storing the filepaths of the geotiff that cover the shapes in each row. Set the geometry with which to find geotiff using `geom_column`. Set the name of the new geotiff_filepath column with `geotiff_filepath_column`. Provide the filepaths of the candidate geotiffs in `geotiff_filepath_list`. All parameters need to be explicitly specified.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39131a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since WSF is in GCS, converting the geometry of the settlements to WGS84 to facilitate spatial matching\n",
    "hamlet_settlements.to_crs('epsg:4326', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1faa6275",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsf_2019_geotiff_filepath_list = glob('./data/WSF2019/*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b1889a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_settlements = add_covering_geotiff_column(hamlet_settlements, \n",
    "                                                 geom_column = 'geometry',\n",
    "                                                 geotiff_filepath_column = 'wsf2019_geotiff_filepath',\n",
    "                                                 geotiff_filepath_list = wsf_2019_geotiff_filepath_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9fdcc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 56/56 [01:23<00:00,  1.49s/it]\n"
     ]
    }
   ],
   "source": [
    "hamlet_settlements = get_raster_value_distribution(hamlet_settlements, \n",
    "                                                   geom_column = 'geometry',\n",
    "                                                   uuid_column = 'mgrs_code',\n",
    "                                                   geotiff_filepath_column = 'wsf2019_geotiff_filepath',\n",
    "                                                   geotiff_filepath_list = wsf_2019_geotiff_filepath_list, \n",
    "                                                   code_to_label_mapping = {0:'no_settlement',255:'settlement'},\n",
    "                                                   label_marker = 'wsf2019',\n",
    "                                                   normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58e76d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_settlements = drop_bounds_columns(hamlet_settlements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b61d6207",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_settlements['wsf_value'] = (hamlet_settlements['wsf2019__settlement']>0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68a24b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_settlements.to_crs(default_pcs, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a90f39d",
   "metadata": {},
   "source": [
    "### Create true positive  / false positive samples based on agreement of sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a51a8341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 618 true positive samples.\n"
     ]
    }
   ],
   "source": [
    "all_agree_positive = hamlet_settlements.query('bp_value == 1 & google_value == 1 & hrsl_value == 1 & wsf_value == 1')\n",
    "print('There are',len(all_agree_positive),'true positive samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68e150ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 148 false positive samples.\n"
     ]
    }
   ],
   "source": [
    "all_agree_negative = hamlet_settlements.query('bp_value == 0 & google_value == 0 & hrsl_value == 0 & wsf_value == 0')\n",
    "print('There are',len(all_agree_negative),'false positive samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c7764e",
   "metadata": {},
   "source": [
    "### Combine manually labeled training data and ruled-based new training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69096b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = gpd.read_file('./data/ZMB_grid3_training_points.geojson')\n",
    "training_data = training_data.query('type == \"hamlet\"')[['mgrs_code','false_posi']]\n",
    "training_data['false_posi'] = training_data['false_posi'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d90a099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_agree_positive = all_agree_positive[['mgrs_code']]\n",
    "all_agree_positive['false_posi'] = 0\n",
    "all_agree_negative = all_agree_negative[['mgrs_code']]\n",
    "all_agree_negative['false_posi'] = 1\n",
    "rule_based_new_training_data = all_agree_positive.append(all_agree_negative, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "947368cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_training_data = training_data.append(rule_based_new_training_data, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6600106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_settlements = hamlet_settlements[['mgrs_code','geometry','wsf2019_geotiff_filepath','wsf2019__no_settlement','wsf2019__settlement']]\n",
    "expanded_training_data = hamlet_settlements.merge(expanded_training_data, on='mgrs_code', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7abfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_training_data.to_feather(X './data/expanded_training_data_v20220509.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc58caa",
   "metadata": {},
   "source": [
    "## Additional features for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "676ab67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_feather('./data/expanded_training_data_v20220509.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41dae306",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = add_buffer_column(gdf, 50)\n",
    "gdf = add_buffer_column(gdf, 500)\n",
    "gdf = add_buffer_column(gdf, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014204c6",
   "metadata": {},
   "source": [
    "### Feature 1: Road count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_road_network = gpd.read_feather('./data/ZMB_mapwithai_road_data_v20200729.feather').to_crs(default_pcs)\n",
    "\n",
    "osm_road_network = gpd.read_feather('./data/ZMB_osm_all_road_network_v20220212.feather').to_crs(default_pcs)\n",
    "\n",
    "for col in gdf.columns:\n",
    "    if col.startswith('geometry_buffer_'):\n",
    "        gdf = add_intersection_count_column(gdf, 'mgrs_code', col, fb_road_network, 'fb_road_within_'+col.replace('geometry_buffer_',''))\n",
    "\n",
    "for col in gdf.columns:\n",
    "    if col.startswith('geometry_buffer_'):\n",
    "        gdf = add_intersection_count_column(gdf, 'mgrs_code', col, osm_road_network, 'osm_road_within_'+col.replace('geometry_buffer_',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979ac96d",
   "metadata": {},
   "source": [
    "### Feature 2: OSM landuse count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_landuse = gpd.read_feather('./data/ZMB_osm_landuse_v20220418.feather').to_crs(default_pcs)\n",
    "\n",
    "common_osm_landuse_categories = ['farmland', 'residential', 'forest']\n",
    "\n",
    "for col in gdf.columns:\n",
    "    if col.startswith('geometry_buffer_'):\n",
    "        for landuse_category in common_osm_landuse_categories:\n",
    "            gdf = add_intersection_count_column(gdf, 'mgrs_code', col, osm_landuse[osm_landuse['landuse']==landuse_category], landuse_category+'_land_use_within_'+col.replace('geometry_buffer_',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f886d6e4",
   "metadata": {},
   "source": [
    "### Feature 3: Distance to nearest settlement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c047be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "settlement_extents = gpd.read_feather('./data/ZMB_grid3_settlement_extents_20201222.feather').to_crs(default_pcs)\n",
    "settlement_extents, centroid_column = add_centroid_column(settlement_extents, return_new_column=True)\n",
    "settlement_extents[centroid_column] = settlement_extents[centroid_column].to_crs('epsg:4326')\n",
    "\n",
    "settlement_extents = add_distance_to_nearest_neighbor_column(settlement_extents, centroid_column, 'distance_to_nearest_settlement')\n",
    "\n",
    "gdf = gdf.merge(settlement_extents[['mgrs_code','distance_to_nearest_settlement']], on='mgrs_code', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec64f73",
   "metadata": {},
   "source": [
    "### Feature 4: ESA landcover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c1f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_crs('epsg:4326', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69030abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "esalc_geotiff_filepath_list = glob('./data/ESA_LC/*_Map.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0c1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = add_covering_geotiff_column(gdf, \n",
    "                                  geom_column = 'geometry',\n",
    "                                  geotiff_filepath_column = 'esalc_geotiff_filepath',\n",
    "                                  geotiff_filepath_list = esalc_geotiff_filepath_list)\n",
    "\n",
    "gdf = gdf.dropna(subset=['esalc_geotiff_filepath'])\n",
    "\n",
    "gdf = get_raster_value_distribution(gdf, \n",
    "                                    geom_column = 'geometry',\n",
    "                                    uuid_column = 'mgrs_code',\n",
    "                                    geotiff_filepath_column = 'esalc_geotiff_filepath',\n",
    "                                    geotiff_filepath_list = esalc_geotiff_filepath_list, \n",
    "                                    code_to_label_mapping = {10: 'forest',\n",
    "                                                             20: 'shrubland',\n",
    "                                                             30: 'grassland',\n",
    "                                                             40: 'cropland',\n",
    "                                                             50: 'built',\n",
    "                                                             60: 'bare',\n",
    "                                                             70: 'ice',\n",
    "                                                             80: 'water',\n",
    "                                                             90: 'wetland',\n",
    "                                                             100: 'tundra',}  ,\n",
    "                                    label_marker = 'esalc',\n",
    "                                    normalize = True)\n",
    "\n",
    "gdf = drop_bounds_columns(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41847868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop land cover ice to avoid perfect colinearity in analysis, also because no where in target country has ice cover\n",
    "gdf = gdf.drop('esalc__ice', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88496a2e",
   "metadata": {},
   "source": [
    "### Feature 5: Google building footprint confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c39bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_building_groupby_stats_df = get_groupby_stats_df(google_buildings_layer, 'mgrs_code', {'area_in_meters':[min,max,np.mean,np.median],'confidence':[min,max,np.mean,np.median]})\n",
    "\n",
    "gdf = pd.merge(gdf, google_building_groupby_stats_df, left_on = 'mgrs_code', right_index = True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_most_correlated_feature(gdf, target = 'false_posi', features = ['area_in_meters__min', 'area_in_meters__max', 'area_in_meters__mean', 'area_in_meters__median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc71f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_most_correlated_feature(gdf, target = 'false_posi', features = ['confidence__min', 'confidence__max', 'confidence__mean', 'confidence__median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9071ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.drop(['area_in_meters__max', 'area_in_meters__mean', 'area_in_meters__median']+['confidence__min', 'confidence__mean', 'confidence__median'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6800e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ab6cdc",
   "metadata": {},
   "source": [
    "### Eliminate non-features and non-indicative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd0b3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf[['mgrs_code', 'false_posi',\n",
    "            'fb_road_within_50', 'fb_road_within_500', 'fb_road_within_5k',\n",
    "            'osm_road_within_50', 'osm_road_within_500', 'osm_road_within_5k',\n",
    "\n",
    "            'farmland_land_use_within_50', 'residential_land_use_within_50', 'forest_land_use_within_50',\n",
    "            'farmland_land_use_within_500', 'residential_land_use_within_500', 'forest_land_use_within_500',\n",
    "            'farmland_land_use_within_5k', 'residential_land_use_within_5k', 'forest_land_use_within_5k',\n",
    "\n",
    "            'esalc__forest', 'esalc__shrubland', 'esalc__grassland',\n",
    "            'esalc__cropland', 'esalc__built', 'esalc__bare', 'esalc__water',\n",
    "            'esalc__wetland', 'esalc__tundra', \n",
    "\n",
    "            'distance_to_nearest_settlement', 'area_in_meters__min', 'confidence__max']]\n",
    "\n",
    "gdf = gdf.set_index('mgrs_code')\n",
    "\n",
    "gdf = gdf.drop(  gdf.nunique()[gdf.nunique() == 1].index.tolist(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb40ceb",
   "metadata": {},
   "source": [
    "### For buffer features, convert from within values to range values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188a5fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = within_value_to_range_value(gdf, buffer_radius_markers = ['within_50','within_500','within_5k'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4631bc",
   "metadata": {},
   "source": [
    "### Reorder feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7993c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf[['false_posi']+sorted([col for col in gdf.columns if col != 'false_posi'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6a801d",
   "metadata": {},
   "source": [
    "### Export dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca4d161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdf.to_csv('./data/cleaned_training_data_v20220509.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
