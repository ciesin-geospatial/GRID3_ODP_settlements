{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5fa726",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d68a0b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geo_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb879e8",
   "metadata": {},
   "source": [
    "### Load settlement data, select the hamlet part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a052ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify country code so all output file will be labeled correctly\n",
    "country_alpha_3_code = 'ZMB'\n",
    "\n",
    "# Specify UTM zone EPSG code for this country, so that projection operation in this notebook knows the target CRS\n",
    "country_utm_epsg = 'epsg:32735'\n",
    "\n",
    "# africa albers equal area conic\n",
    "albers_equal_area = 'epsg:102022' # not found\n",
    "\n",
    "default_pcs = country_utm_epsg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d862dbf",
   "metadata": {},
   "source": [
    "---\n",
    "Function `explode_geometry`\n",
    "\n",
    "Parameters: \n",
    "- `gdf`, *GeoDataframe* \n",
    "- `geom_colum`, *str*   (default = 'geometry') \n",
    "- `id_column`, *str*   (default = None, must specify if using drop_duplicates) \n",
    "- `drop_duplicates`, *boolean*   (default = False) \n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe with geometry column exploded into single-polygon/single-linestring objects. Use drop_duplicates in combination with id_column to keep only the the largest shape among the shapes with the same original id.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edce01c5",
   "metadata": {},
   "source": [
    "---\n",
    "Function `add_buffer_column`\n",
    "\n",
    "Parameters: \n",
    "- `gdf`, *GeoDataframe* \n",
    "- `buffer_radius`, *int*  (in meters)\n",
    "- `geom_column`, *str*   (default = 'geometry') \n",
    "- `buffer_shape`, *str*   (default = 'round', options: 'round','square','flat') \n",
    "- `proj2`, *str* (default = None, options: any valid crs)\n",
    "- `replace`, *boolean* (default = False)\n",
    "- `return_new_column`, *boolean* (default = False)\n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe with a new buffer column. Set the geometry from which to buffer using `geom_column`. Set buffer radius with `buffer_radius`, units are in meters, the radius can be negative for shrinking shapes, though multiple shapes may be created as a result. Control shape of buffer with `buffer_shape`. If you want the buffer to be based on a projection other than current projection, use `proj2`, it will not affect the projection of the input dataframe, it only applies to the new buffer column. If you want to replace the main geometry column with the newly created buffer column, set `replace` to True. If you want to get the name of the newly created buffer column, set `return_new_column` to True. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbc7e00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the shapefile of all settlements\n",
    "settlement_extents = gpd.read_feather('./data/ZMB_grid3_settlement_extents_20201222.feather').to_crs(default_pcs)\n",
    "\n",
    "# Filter down to hamlet settlements (the focus of this false positive prediction workflow)\n",
    "hamlet_settlements = settlement_extents.query('type == \"hamlet\"')[['mgrs_code','geometry']]\n",
    "\n",
    "# Convert the default \"multipolygon\" geometry type to (single)\"polygon\" geometry type\n",
    "hamlet_settlements = explode_geometry(hamlet_settlements, id_column = 'mgrs_code', drop_duplicates = True)\n",
    "\n",
    "hamlet_settlements = add_buffer_column(hamlet_settlements, -40, proj2=None, replace=True)\n",
    "\n",
    "hamlet_settlements = explode_geometry(hamlet_settlements, id_column = 'mgrs_code', drop_duplicates = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eb50f3",
   "metadata": {},
   "source": [
    "### Feature 1:  Google building presence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f3643e",
   "metadata": {},
   "source": [
    "---\n",
    "Function `read_csv_as_gpd`\n",
    "\n",
    "Parameters: \n",
    "- `df_or_filepath`, *GeoDataframe or str*\n",
    "- `id_column`, *str*   (default = None, if not specified, a UUID column will be generated) \n",
    "- `lon_lat_columns`, *list of str*   (default = \\[\\]) \n",
    "- `attribute_columns`, *list of str*  (default = \\[\\]) \n",
    "- `drop_rows_where_duplicates_in_columns`, *list of str*  (default = \\[\\]) \n",
    "- `keep_which_if_duplicates`, *str*  (default = 'first', options: 'first','last')\n",
    "- `drop_rows_where_nan_in_columns`, *list of str*  (default = \\[\\]) \n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe loaded from a CSV file. Use `drop_rows_where_duplicates_in_columns` in combination with `id_column` and `keep_which_if_duplicates` to keep control the behavior when duplicates are detected in certain columns. Use `drop_rows_where_nan_in_columns` to control the dropping of rows with missing values.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cd12ce",
   "metadata": {},
   "source": [
    "---\n",
    "Function `left_spatial_join`\n",
    "\n",
    "Parameters: \n",
    "- `gdf1`, *GeoDataframe*\n",
    "- `gdf2`, *GeoDataframe*   \n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe resulting from the left spatial join of two input GeoDataframes. Spatial join operation uses \"intersection\", right index dropped.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "538fb426",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_buildings_layer = read_csv_as_gpd('./data/ZMB_google_buildings_footprint.csv', \n",
    "                                          id_column = None, \n",
    "                                          lon_lat_columns = ['longitude','latitude'], \n",
    "                                          attribute_columns = ['area_in_meters','confidence'],\n",
    "                                          drop_rows_where_duplicates_in_columns = ['longitude','latitude']\n",
    "                                        ).to_crs(default_pcs)\n",
    "\n",
    "google_buildings_layer = left_spatial_join(google_buildings_layer, hamlet_settlements[['mgrs_code','geometry']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e41b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "settlements_with_google_builing = google_buildings_layer['mgrs_code'].dropna().unique().tolist()\n",
    "\n",
    "hamlet_settlements.loc[hamlet_settlements['mgrs_code'].isin(settlements_with_google_builing),'google_value'] = 1\n",
    "hamlet_settlements['google_value'] = hamlet_settlements['google_value'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedb9c0b",
   "metadata": {},
   "source": [
    "### Feature 2: Survey building presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_presence_layer = read_csv_as_gpd('./data/ZM_geos_L1_2019.csv', \n",
    "                                          id_column = 'sid', \n",
    "                                          lon_lat_columns = ['lon','lat'], \n",
    "                                          attribute_columns = ['bp'], \n",
    "                                          drop_rows_where_duplicates_in_columns = ['observer','lat','lon'], \n",
    "                                          drop_rows_where_nan_in_columns = ['lat','lon','bp']\n",
    "                                         ).to_crs(default_pcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "building_presence_layer = add_buffer_column(building_presence_layer, buffer_radius = 100, buffer_shape = 'square', replace=True)\n",
    "\n",
    "hamlet_settlements = left_spatial_join(hamlet_settlements, building_presence_layer[['bp','geometry']])\n",
    "\n",
    "hamlet_settlements['bp_value'] = hamlet_settlements['bp'].map({'Y':1,'N':0})\n",
    "\n",
    "hamlet_settlements = hamlet_settlements.drop('bp', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a3560f",
   "metadata": {},
   "source": [
    "### Feature 3: HRSL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d4d0c9",
   "metadata": {},
   "source": [
    "---\n",
    "Function `add_centroid_column`\n",
    "\n",
    "Parameters: \n",
    "- `gdf`, *GeoDataframe* \n",
    "- `geom_column`, *str*   (default = 'geometry') \n",
    "- `proj2`, *str* (default = None, options: any valid crs)\n",
    "- `replace`, *boolean* (default = False)\n",
    "- `return_new_column`, *boolean* (default = False)\n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe with a new centroid column. Set the geometry from which to calculate centroid using `geom_column`. If you want the centroid to be based on a projection other than current projection, use `proj2`, it will not affect the projection of the input dataframe, it only applies to the new centroid column. If you want to replace the main geometry column with the newly created centroid column, set `replace` to True. If you want to get the name of the newly created centroid column, set `return_new_column` to True. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f66236",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_settlements, centroid_column = add_centroid_column(hamlet_settlements, return_new_column=True)\n",
    "\n",
    "# Since HRSL data is in GCS, convert just the centroid column to WGS84 to facilitate pixel lookup in HRSL raster\n",
    "hamlet_settlements[centroid_column] = hamlet_settlements[centroid_column].to_crs('epsg:4326')\n",
    "\n",
    "hamlet_settlements = get_raster_point_value(hamlet_settlements, centroid_column, raster_filepath = './data/ZMB_HRSL_hasim_20211222.tif', new_column = 'hrsl_value')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd802bb",
   "metadata": {},
   "source": [
    "### Feature 4: WSF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887c24d2",
   "metadata": {},
   "source": [
    "---\n",
    "Function `add_covering_geotiff_column`\n",
    "\n",
    "Parameters: \n",
    "- `gdf`, *GeoDataframe* \n",
    "- `geom_column`, *str* \n",
    "- `geotiff_filepath_column`, *str*\n",
    "- `geotiff_filepath_list`, *list of str* \n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe with a new column storing the filepaths of the geotiff that cover the shapes in each row. Set the geometry with which to find geotiff using `geom_column`. Set the name of the new geotiff_filepath column with `geotiff_filepath_column`. Provide the filepaths of the candidate geotiffs in `geotiff_filepath_list`. All parameters need to be explicitly specified.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75cf796",
   "metadata": {},
   "source": [
    "---\n",
    "Function `get_raster_value_distribution`\n",
    "\n",
    "Parameters: \n",
    "- `gdf`, *GeoDataframe* \n",
    "- `id_column`, *str*\n",
    "- `geom_column`, *str* \n",
    "- `geotiff_filepath_column`, *str*\n",
    "- `geotiff_filepath_list`, *list of str* \n",
    "- `code_to_label_mapping`, *list of str* \n",
    "- `label_marker`, *list of str* \n",
    "- `normalize`, *boolean* \n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe with new columns corresponding to the distribution of different codes in the covering raster image. Specify which raster geotiff is covering the geometry with `geotiff_filepath_column`. Provide the filepaths of the candidate geotiffs in `geotiff_filepath_list`. Use `code_to_label_mapping` to specify the mapping from numerical codes to human-readable labels, this may vary from one standard to another. `label_marker` is a prefix to all the newly-created column, so as to mark which raster these columns are derived from. `normalize` controls whether the values in the columns are proportion or absolute count of pixels. All parameters need to be explicitly specified.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39131a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since WSF is in GCS, converting the geometry of the settlements to WGS84 to facilitate spatial matching\n",
    "hamlet_settlements.to_crs('epsg:4326', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faa6275",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsf_2019_geotiff_filepath_list = glob('./data/WSF2019/*.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1889a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_settlements = add_covering_geotiff_column(hamlet_settlements, \n",
    "                                                 geom_column = 'geometry',\n",
    "                                                 geotiff_filepath_column = 'wsf2019_geotiff_filepath',\n",
    "                                                 geotiff_filepath_list = wsf_2019_geotiff_filepath_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fdcc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_settlements = get_raster_value_distribution(hamlet_settlements, \n",
    "                                                   id_column = 'mgrs_code',\n",
    "                                                   geom_column = 'geometry',\n",
    "                                                   geotiff_filepath_column = 'wsf2019_geotiff_filepath',\n",
    "                                                   geotiff_filepath_list = wsf_2019_geotiff_filepath_list, \n",
    "                                                   code_to_label_mapping = {0:'no_settlement',255:'settlement'},\n",
    "                                                   label_marker = 'wsf2019',\n",
    "                                                   normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dface7b",
   "metadata": {},
   "source": [
    "---\n",
    "Function `drop_bounds`\n",
    "\n",
    "Parameters: \n",
    "- `gdf`, *GeoDataframe* \n",
    "- `geom_column`, *str* \n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe with geometry bounds columns dropped, these include the columns that start with a geometry column name and end with `minx`, `maxx`, `miny`, or `maxy`. This is a utility function to help similify output of `get_raster_value_distribution` function.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e76d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_settlements = drop_bounds_columns(hamlet_settlements, geom_column='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d6207",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_settlements['wsf_value'] = (hamlet_settlements['wsf2019__settlement']>0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a24b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_settlements.to_crs(default_pcs, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a90f39d",
   "metadata": {},
   "source": [
    "### Create true positive  / false positive samples based on agreement of sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51a8341",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_agree_positive = hamlet_settlements.query('bp_value == 1 & google_value == 1 & hrsl_value == 1 & wsf_value == 1')\n",
    "print('There are',len(all_agree_positive),'true positive samples.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e150ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_agree_negative = hamlet_settlements.query('bp_value == 0 & google_value == 0 & hrsl_value == 0 & wsf_value == 0')\n",
    "print('There are',len(all_agree_negative),'false positive samples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c7764e",
   "metadata": {},
   "source": [
    "### Combine manually labeled training data and ruled-based new training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69096b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = gpd.read_file('./data/ZMB_grid3_training_points.geojson')\n",
    "training_data = training_data.query('type == \"hamlet\"')[['mgrs_code','false_posi']]\n",
    "training_data['false_posi'] = training_data['false_posi'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90a099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_agree_positive = all_agree_positive[['mgrs_code']]\n",
    "all_agree_positive['false_posi'] = 0\n",
    "all_agree_negative = all_agree_negative[['mgrs_code']]\n",
    "all_agree_negative['false_posi'] = 1\n",
    "rule_based_new_training_data = all_agree_positive.append(all_agree_negative, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947368cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_training_data = training_data.append(rule_based_new_training_data, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6600106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamlet_settlements = hamlet_settlements[['mgrs_code','geometry','wsf2019_geotiff_filepath','wsf2019__no_settlement','wsf2019__settlement']]\n",
    "expanded_training_data = hamlet_settlements.merge(expanded_training_data, on='mgrs_code', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085a6ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_training_data.to_feather(X './data/expanded_training_data_v20220509.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc58caa",
   "metadata": {},
   "source": [
    "## Additional features for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "676ab67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = gpd.read_feather('./data/expanded_training_data_v20220509.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37c2db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = hamlet_settlements.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41dae306",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = add_buffer_column(gdf, 50)\n",
    "gdf = add_buffer_column(gdf, 500)\n",
    "gdf = add_buffer_column(gdf, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d740fa",
   "metadata": {},
   "source": [
    "---\n",
    "Function `add_intersection_count_column`\n",
    "\n",
    "Parameters:\n",
    "- `gdf`, *GeoDataframe* \n",
    "- `uuid_column`, *str* \n",
    "- `buffer_column`, *str* \n",
    "- `feature_layer`, *str* \n",
    "- `new_column`, *str* \n",
    "- `feature_geom_column`, *str* (default = 'geometry')\n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe with a new column that counts the feature geometries within the buffer of main geometry. `gdf` is the main GeoDataframe that has a buffer column, specified by `buffer_column`. `feature_layer` is the other GEoDataframe with features, by default the 'geometry' column of the feature layer will be used but it can be changed. `new_column` controls the name of the newly-created column.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014204c6",
   "metadata": {},
   "source": [
    "### Feature 1: Road count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59ec572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_road_network = gpd.read_feather('./data/ZMB_mapwithai_road_data_v20200729.feather').to_crs(default_pcs)\n",
    "\n",
    "osm_road_network = gpd.read_feather('./data/ZMB_osm_all_road_network_v20220212.feather').to_crs(default_pcs)\n",
    "\n",
    "for col in gdf.columns:\n",
    "    if col.startswith('geometry_buffer_'):\n",
    "        gdf = add_intersection_count_column(gdf, 'mgrs_code', col, fb_road_network, 'fb_road_within_'+col.replace('geometry_buffer_',''))\n",
    "\n",
    "for col in gdf.columns:\n",
    "    if col.startswith('geometry_buffer_'):\n",
    "        gdf = add_intersection_count_column(gdf, 'mgrs_code', col, osm_road_network, 'osm_road_within_'+col.replace('geometry_buffer_',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979ac96d",
   "metadata": {},
   "source": [
    "### Feature 2: OSM landuse count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a02f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "osm_landuse = gpd.read_feather('./data/ZMB_osm_landuse_v20220418.feather').to_crs(default_pcs)\n",
    "\n",
    "common_osm_landuse_categories = ['farmland', 'residential', 'forest']\n",
    "\n",
    "for col in gdf.columns:\n",
    "    if col.startswith('geometry_buffer_'):\n",
    "        for landuse_category in common_osm_landuse_categories:\n",
    "            gdf = add_intersection_count_column(gdf, 'mgrs_code', col, osm_landuse[osm_landuse['landuse']==landuse_category], landuse_category+'_land_use_within_'+col.replace('geometry_buffer_',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f886d6e4",
   "metadata": {},
   "source": [
    "### Feature 3: Distance to nearest settlement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f7433a",
   "metadata": {},
   "source": [
    "---\n",
    "Function `add_distance_to_nearest_neighbor_column`\n",
    "\n",
    "Parameters:\n",
    "- `gdf`, *GeoDataframe* \n",
    "- `geom_centroid_column`, *str* \n",
    "- `new_column`, *str* \n",
    "- `rounding`, *str* (default = 0)\n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe with a new column that calculate the distance from this geometry to the nearest geometry within the same GeoDataframe. Use `geom_centroid_column` to specify which geometry to do nearest distance calculation. `new_column` controls the name of the newly-created column. The distance is measured in meters and rounded by default, but can be changed with `rounding` parameter. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c047be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "settlement_extents = gpd.read_feather('./data/ZMB_grid3_settlement_extents_20201222.feather').to_crs(default_pcs)\n",
    "settlement_extents, centroid_column = add_centroid_column(settlement_extents, return_new_column=True)\n",
    "settlement_extents[centroid_column] = settlement_extents[centroid_column].to_crs('epsg:4326')\n",
    "\n",
    "settlement_extents = add_distance_to_nearest_neighbor_column(settlement_extents, centroid_column, 'distance_to_nearest_settlement')\n",
    "\n",
    "gdf = gdf.merge(settlement_extents[['mgrs_code','distance_to_nearest_settlement']], on='mgrs_code', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec64f73",
   "metadata": {},
   "source": [
    "### Feature 4: ESA landcover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8c1f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_crs('epsg:4326', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69030abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "esalc_geotiff_filepath_list = glob('./data/ESA_LC/*_Map.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d0c1a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 12/12 [01:20<00:00,  6.69s/it]\n"
     ]
    }
   ],
   "source": [
    "# gdf = add_covering_geotiff_column(gdf, \n",
    "#                                   geom_column = 'geometry',\n",
    "#                                   geotiff_filepath_column = 'esalc_geotiff_filepath',\n",
    "#                                   geotiff_filepath_list = esalc_geotiff_filepath_list)\n",
    "\n",
    "# gdf = gdf.dropna(subset=['esalc_geotiff_filepath'])\n",
    "\n",
    "gdf = get_raster_value_distribution(gdf, \n",
    "                                    geom_column = 'geometry',\n",
    "                                    uuid_column = 'mgrs_code',\n",
    "                                    geotiff_filepath_column = 'esalc_geotiff_filepath',\n",
    "                                    geotiff_filepath_list = esalc_geotiff_filepath_list, \n",
    "                                    code_to_label_mapping = {10: 'forest',\n",
    "                                                             20: 'shrubland',\n",
    "                                                             30: 'grassland',\n",
    "                                                             40: 'cropland',\n",
    "                                                             50: 'built',\n",
    "                                                             60: 'bare',\n",
    "                                                             70: 'ice',\n",
    "                                                             80: 'water',\n",
    "                                                             90: 'wetland',\n",
    "                                                             100: 'tundra',}  ,\n",
    "                                    label_marker = 'esalc',\n",
    "                                    normalize = True)\n",
    "\n",
    "gdf = drop_bounds_columns(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f459fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop land cover ice to avoid perfect colinearity in analysis, also because no where in target country has ice cover\n",
    "gdf = gdf.drop('esalc__ice', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88496a2e",
   "metadata": {},
   "source": [
    "### Feature 5: Google building footprint confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850b168b",
   "metadata": {},
   "source": [
    "---\n",
    "Function `get_groupby_stats_df`\n",
    "\n",
    "Parameters:\n",
    "- `data`, *Dataframe or GeoDataframe* \n",
    "- `groupby_column`, *str* \n",
    "- `stats_map`, *dict* \n",
    "\n",
    "Returns: \n",
    "- A Dataframe with statistics of the provided features, a simple wrapper around Pandas `groupby` function.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31c39bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_building_groupby_stats_df = get_groupby_stats_df(google_buildings_layer, 'mgrs_code', {'area_in_meters':[min],'confidence':[max]})\n",
    "\n",
    "gdf = pd.merge(gdf, google_building_groupby_stats_df, left_on = 'mgrs_code', right_index = True, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2acacc3",
   "metadata": {},
   "source": [
    "---\n",
    "Function `get_most_correlated_feature`\n",
    "\n",
    "Parameters:\n",
    "- `data`, *Dataframe or GeoDataframe* \n",
    "- `target`, *str* \n",
    "- `features`, *list of str* \n",
    "\n",
    "Returns: \n",
    "- The name of feature that is most correlated with the target, as measured by Pearson R. This is a simple utility function for choosing one feature when several features are highly correlated with each other.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85364098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(get_most_correlated_feature(gdf, target = 'false_posi', features = ['area_in_meters__min', 'area_in_meters__max', 'area_in_meters__mean', 'area_in_meters__median']))\n",
    "\n",
    "# print(get_most_correlated_feature(gdf, target = 'false_posi', features = ['confidence__min', 'confidence__max', 'confidence__mean', 'confidence__median']))\n",
    "\n",
    "# gdf = gdf.drop(['area_in_meters__max', 'area_in_meters__mean', 'area_in_meters__median']+['confidence__min', 'confidence__mean', 'confidence__median'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea5053a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gdf.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb10dd8",
   "metadata": {},
   "source": [
    "### Eliminate non-features and non-indicative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d32722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = gdf[['mgrs_code', 'false_posi',\n",
    "#             'fb_road_within_50', 'fb_road_within_500', 'fb_road_within_5k',\n",
    "#             'osm_road_within_50', 'osm_road_within_500', 'osm_road_within_5k',\n",
    "\n",
    "#             'farmland_land_use_within_50', 'residential_land_use_within_50', 'forest_land_use_within_50',\n",
    "#             'farmland_land_use_within_500', 'residential_land_use_within_500', 'forest_land_use_within_500',\n",
    "#             'farmland_land_use_within_5k', 'residential_land_use_within_5k', 'forest_land_use_within_5k',\n",
    "\n",
    "#             'esalc__forest', 'esalc__shrubland', 'esalc__grassland',\n",
    "#             'esalc__cropland', 'esalc__built', 'esalc__bare', 'esalc__water',\n",
    "#             'esalc__wetland', 'esalc__tundra', \n",
    "\n",
    "#             'distance_to_nearest_settlement', 'area_in_meters__min', 'confidence__max']]\n",
    "\n",
    "gdf = gdf[['mgrs_code','area_in_meters__min',\n",
    " 'confidence__max',\n",
    " 'distance_to_nearest_settlement',\n",
    " 'esalc__bare',\n",
    " 'esalc__built',\n",
    " 'esalc__cropland',\n",
    " 'esalc__forest',\n",
    " 'esalc__grassland',\n",
    " 'esalc__shrubland',\n",
    " 'esalc__water',\n",
    " 'esalc__wetland',\n",
    " 'farmland_land_use_within_50',\n",
    " 'farmland_land_use_within_500',\n",
    " 'farmland_land_use_within_5k',\n",
    " 'fb_road_within_50',\n",
    " 'fb_road_within_500',\n",
    " 'fb_road_within_5k',\n",
    " 'forest_land_use_within_50',\n",
    " 'forest_land_use_within_500',\n",
    " 'forest_land_use_within_5k',\n",
    " 'osm_road_within_50',\n",
    " 'osm_road_within_500',\n",
    " 'osm_road_within_5k',\n",
    " 'residential_land_use_within_50',\n",
    " 'residential_land_use_within_500',\n",
    " 'residential_land_use_within_5k']]\n",
    "\n",
    "gdf = gdf.set_index('mgrs_code')\n",
    "\n",
    "# gdf = gdf.drop(  gdf.nunique()[gdf.nunique() == 1].index.tolist(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3b1c8",
   "metadata": {},
   "source": [
    "### For buffer features, convert from within values to range values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e2213e",
   "metadata": {},
   "source": [
    "---\n",
    "Function `within_value_to_range_value`\n",
    "\n",
    "Parameters:\n",
    "- `gdf`, *GeoDataframe* \n",
    "- `buffer_radius_markers`, *str* \n",
    "\n",
    "Returns: \n",
    "- A GeoDataframe with new columns tracking the count of features in the ring areas around main geometries. For example, the number of features in the ring area that is at least 500 meters away but at most 5000 meters away from a settlement. This is based on the observation that number of features within 5000 meters must include the number of features within 500 meters, which creates collinearity that hurts prediction models. Thus, this function calculates the count in a specific range instead of the count within a radius.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ed95f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = within_value_to_range_value(gdf, buffer_radius_markers = ['within_50','within_500','within_5k'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41590700",
   "metadata": {},
   "source": [
    "### Reorder feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8aabac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf = gdf[['false_posi']+sorted([col for col in gdf.columns if col != 'false_posi'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27299204",
   "metadata": {},
   "source": [
    "### Export dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9761afe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdf.to_csv('./data/cleaned_all_hamlet_data_v20220521.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
